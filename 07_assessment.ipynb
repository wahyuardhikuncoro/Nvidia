{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ImageNet Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we suggest freezing the base model, as done in [notebook 05b](05b_presidential_doggy_door.ipynb). This is done so that all the learning from the ImageNet dataset does not get destroyed in the initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Layers to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to add layers to the pretrained model. [Notebook 05b](05b_presidential_doggy_door.ipynb) can be used as a guide. Pay close attention to the last dense layer and make sure it has the correct number of neurons to classify the different types of fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = keras.Input(shape=(224,224,3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = keras.layers.Dense(6, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 14,717,766\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compile the model with loss and metrics options. Remember that we're training on a number of different categories, rather than a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like, try to augment the data to improve the dataset. Feel free to look at [notebook 04a](04a_asl_augmentation.ipynb) and [notebook 05b](05b_presidential_doggy_door.ipynb) for augmentation examples. There is also documentation for the [Keras ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class). This step is optional, but it may be helpful to get to 92% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the train and validation datasets. Pick the right folders, as well as the right `target_size` of the images (it needs to match the height and width input of the model you've created). If you'd like a reference, you can check out [notebook 05b](05b_presidential_doggy_door.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1182 images belonging to 6 classes.\n",
      "Found 329 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('data/fruits/train/', \n",
    "                                       target_size=(224,224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode=\"categorical\")\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen.flow_from_directory('data/fruits/valid/', \n",
    "                                      target_size=(224,224), \n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the model! Pass the `train` and `valid` iterators into the `fit` function, as well as setting your desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/36 [==============================] - 28s 753ms/step - loss: 2.1666 - accuracy: 0.5118 - val_loss: 0.9729 - val_accuracy: 0.7356\n",
      "Epoch 2/20\n",
      "37/36 [==============================] - 20s 531ms/step - loss: 0.7954 - accuracy: 0.7614 - val_loss: 0.5207 - val_accuracy: 0.8480\n",
      "Epoch 3/20\n",
      "37/36 [==============================] - 20s 529ms/step - loss: 0.4558 - accuracy: 0.8503 - val_loss: 0.4017 - val_accuracy: 0.8693\n",
      "Epoch 4/20\n",
      "37/36 [==============================] - 20s 529ms/step - loss: 0.2778 - accuracy: 0.9086 - val_loss: 0.2285 - val_accuracy: 0.9210\n",
      "Epoch 5/20\n",
      "37/36 [==============================] - 20s 531ms/step - loss: 0.2003 - accuracy: 0.9255 - val_loss: 0.2924 - val_accuracy: 0.8997\n",
      "Epoch 6/20\n",
      "37/36 [==============================] - 20s 528ms/step - loss: 0.1461 - accuracy: 0.9467 - val_loss: 0.1260 - val_accuracy: 0.9483\n",
      "Epoch 7/20\n",
      "37/36 [==============================] - 20s 532ms/step - loss: 0.1177 - accuracy: 0.9602 - val_loss: 0.1254 - val_accuracy: 0.9574\n",
      "Epoch 8/20\n",
      "37/36 [==============================] - 19s 527ms/step - loss: 0.0878 - accuracy: 0.9653 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
      "Epoch 9/20\n",
      "37/36 [==============================] - 20s 529ms/step - loss: 0.0841 - accuracy: 0.9687 - val_loss: 0.1724 - val_accuracy: 0.9483\n",
      "Epoch 10/20\n",
      "37/36 [==============================] - 19s 527ms/step - loss: 0.0783 - accuracy: 0.9704 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
      "Epoch 11/20\n",
      "37/36 [==============================] - 19s 522ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 0.1224 - val_accuracy: 0.9574\n",
      "Epoch 12/20\n",
      "37/36 [==============================] - 20s 528ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.1455 - val_accuracy: 0.9544\n",
      "Epoch 13/20\n",
      "37/36 [==============================] - 20s 529ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.0801 - val_accuracy: 0.9787\n",
      "Epoch 14/20\n",
      "37/36 [==============================] - 20s 532ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "37/36 [==============================] - 20s 529ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.1140 - val_accuracy: 0.9666\n",
      "Epoch 16/20\n",
      "37/36 [==============================] - 20s 530ms/step - loss: 0.0262 - accuracy: 0.9949 - val_loss: 0.0730 - val_accuracy: 0.9818\n",
      "Epoch 17/20\n",
      "37/36 [==============================] - 20s 527ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.1133 - val_accuracy: 0.9635\n",
      "Epoch 18/20\n",
      "37/36 [==============================] - 20s 530ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.1259 - val_accuracy: 0.9726\n",
      "Epoch 19/20\n",
      "37/36 [==============================] - 20s 530ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.1531 - val_accuracy: 0.9666\n",
      "Epoch 20/20\n",
      "37/36 [==============================] - 20s 530ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.0729 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2ac87dee80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "          validation_data=valid_it,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze Model for Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have reached 92% validation accuracy already, this next step is optional. If not, we suggest fine tuning the model with a very low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = FIXME\n",
    "\n",
    "# Compile the model with a low learning rate\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = FIXME),\n",
    "              loss = FIXME , metrics = FIXME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(FIXME,\n",
    "          validation_data=FIXME,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs=FIXME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you now have a model that has a validation accuracy of 92% or higher. If not, you may want to go back and either run more epochs of training, or adjust your data augmentation. \n",
    "\n",
    "Once you are satisfied with the validation accuracy, evaluate the model by executing the following cell. The evaluate function will return a tuple, where the first value is your loss, and the second value is your accuracy. To pass, the model will need have an accuracy value of `92% or higher`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/10 [================================] - 4s 350ms/step - loss: 0.1215 - accuracy: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12153420597314835, 0.9696048498153687]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess your model run the following two cells.\n",
    "\n",
    "**NOTE:** `run_assessment` assumes your model is named `model` and your validation data iterator is called `valid_it`. If for any reason you have modified these variable names, please update the names of the arguments passed to `run_assessment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_assessment import run_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 5 times to obtain average accuracy...\n",
      "\n",
      "11/10 [================================] - 4s 383ms/step - loss: 0.1067 - accuracy: 0.9696\n",
      "11/10 [================================] - 4s 343ms/step - loss: 0.1131 - accuracy: 0.9787\n",
      "11/10 [================================] - 4s 351ms/step - loss: 0.0872 - accuracy: 0.9757\n",
      "11/10 [================================] - 4s 363ms/step - loss: 0.1026 - accuracy: 0.9757\n",
      "11/10 [================================] - 4s 345ms/step - loss: 0.1158 - accuracy: 0.9726\n",
      "\n",
      "Accuracy required to pass the assessment is 0.92 or greater.\n",
      "Your average accuracy is 0.9745.\n",
      "\n",
      "Congratulations! You passed the assessment!\n",
      "See instructions below to generate a certificate.\n"
     ]
    }
   ],
   "source": [
    "run_assessment(model, valid_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
